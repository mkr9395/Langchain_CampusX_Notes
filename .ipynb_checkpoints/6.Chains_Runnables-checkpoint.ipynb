{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4cd4131",
   "metadata": {},
   "source": [
    "# SESSION 7 : Chains in LangChain | Generative AI using LangChain | Video 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899ffa4",
   "metadata": {},
   "source": [
    "https://youtu.be/5hjrPILA3-8?list=PLKnIA16_RmvaTbihpo4MtzVm4XOQa0ER0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0534a1",
   "metadata": {},
   "source": [
    "**Chains** are the **core abstraction** in LangChain, and understanding them makes it way easier to build real-world apps with LLMs.\n",
    "\n",
    "\n",
    "* A **Chain** is a sequence of steps (or components) where the **output of one step becomes the input of the next**.\n",
    "\n",
    "\n",
    "* They connect LLMs, prompts, parsers, retrievers, tools, etc.\n",
    "\n",
    "\n",
    "* Instead of writing ad-hoc glue code, LangChain gives reusable **chain classes**.\n",
    "\n",
    "ðŸ‘‰ Think of chains as **pipelines for LLM workflows**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dd0f81",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Types of Chains in LangChain\n",
    "\n",
    "There are multiple built-in types. Letâ€™s cover the main ones:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa774e6",
   "metadata": {},
   "source": [
    "### 1. **LLMChain**\n",
    "\n",
    "* Simplest chain: **PromptTemplate â†’ LLM â†’ Output**.\n",
    "\n",
    "* Used for text generation or simple Q\\&A.\n",
    "\n",
    "```python\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "prompt = PromptTemplate.from_template(\"Translate this to French: {text}\")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "print(chain.run(\"I love programming\"))\n",
    "# â†’ \"J'adore la programmation\"\n",
    "```\n",
    "\n",
    "âœ… Use when you just need one prompt + one LLM call."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7d63da",
   "metadata": {},
   "source": [
    "### 2. **SimpleSequentialChain**\n",
    "\n",
    "* Runs multiple chains **sequentially**.\n",
    "* Each chainâ€™s output becomes the next chainâ€™s input.\n",
    "\n",
    "```python\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain1 = LLMChain(llm=llm, prompt=PromptTemplate.from_template(\"Summarize: {text}\"))\n",
    "chain2 = LLMChain(llm=llm, prompt=PromptTemplate.from_template(\"Translate to Spanish: {text}\"))\n",
    "\n",
    "overall_chain = SimpleSequentialChain(chains=[chain1, chain2])\n",
    "\n",
    "print(overall_chain.run(\"LangChain makes building LLM apps easy.\"))\n",
    "# â†’ \"LangChain facilita la creaciÃ³n de aplicaciones LLM.\"\n",
    "```\n",
    "\n",
    "âœ… Use when you have a **linear pipeline** of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970578c4",
   "metadata": {},
   "source": [
    "### 3. **SequentialChain (a.k.a. MultiInput/Output Chains)**\n",
    "\n",
    "* Like `SimpleSequentialChain`, but allows **multiple inputs/outputs**.\n",
    "* You can pass data between steps explicitly.\n",
    "\n",
    "```python\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "summarize_prompt = PromptTemplate.from_template(\"Summarize: {text}\")\n",
    "translate_prompt = PromptTemplate.from_template(\"Translate summary to German: {summary}\")\n",
    "\n",
    "chain1 = LLMChain(llm=llm, prompt=summarize_prompt, output_key=\"summary\")\n",
    "chain2 = LLMChain(llm=llm, prompt=translate_prompt, output_key=\"translated_summary\")\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain1, chain2],\n",
    "    input_variables=[\"text\"],\n",
    "    output_variables=[\"summary\", \"translated_summary\"]\n",
    ")\n",
    "\n",
    "print(overall_chain.run(\"LangChain is a framework for building applications with LLMs.\"))\n",
    "# â†’ {'summary': 'LangChain is a framework for LLM apps.', 'translated_summary': 'LangChain ist ein Framework fÃ¼r LLM-Anwendungen.'}\n",
    "```\n",
    "\n",
    "âœ… Use when you need **multiple fields flowing between steps**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17820e1",
   "metadata": {},
   "source": [
    "### 4. **TransformChain**\n",
    "\n",
    "* Applies a **custom Python function** as a step.\n",
    "* Useful for formatting, cleaning, or data transformations.\n",
    "\n",
    "```python\n",
    "from langchain.chains import TransformChain\n",
    "\n",
    "def lowercase(inputs):\n",
    "    return {\"text\": inputs[\"text\"].lower()}\n",
    "\n",
    "chain = TransformChain(input_variables=[\"text\"], output_variables=[\"text\"], transform=lowercase)\n",
    "\n",
    "print(chain.run({\"text\": \"HELLO WORLD\"}))\n",
    "# â†’ {\"text\": \"hello world\"}\n",
    "```\n",
    "\n",
    "âœ… Use when you need **custom preprocessing or postprocessing**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713ef384",
   "metadata": {},
   "source": [
    "### 5. **RouterChain**\n",
    "\n",
    "* Dynamically routes input to **different chains** based on conditions (often via LLM decision-making).\n",
    "\n",
    "Example:\n",
    "\n",
    "* If input is `\"Translate to French\"` â†’ go to translation chain.\n",
    "* If input is `\"Summarize this\"` â†’ go to summarization chain.\n",
    "\n",
    "âœ… Use when you have **multiple tasks** and need smart routing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea119522",
   "metadata": {},
   "source": [
    "### 6. **RetrievalQAChain**\n",
    "\n",
    "* Combines **retrievers (RAG)** with an LLM.\n",
    "* Retrieves documents from a vector DB â†’ feeds into LLM â†’ outputs answer.\n",
    "\n",
    "```python\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)\n",
    "\n",
    "print(qa_chain.run(\"What is LangChain?\"))\n",
    "```\n",
    "\n",
    "âœ… Use when doing **question-answering over documents**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5354be",
   "metadata": {},
   "source": [
    "### 7. **Custom Chains**\n",
    "\n",
    "* You can also build your own by subclassing `Chain`.\n",
    "* Useful when built-ins donâ€™t cover your workflow.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”¹ When to Use Which?\n",
    "\n",
    "* **LLMChain** â†’ one prompt, one LLM call.\n",
    "\n",
    "\n",
    "* **SimpleSequentialChain** â†’ straight pipeline, one output â†’ next input.\n",
    "\n",
    "\n",
    "* **SequentialChain** â†’ pipeline with multiple input/output variables.\n",
    "\n",
    "\n",
    "* **TransformChain** â†’ inject custom Python logic.\n",
    "\n",
    "\n",
    "* **RouterChain** â†’ dynamic branching / multiple possible paths.\n",
    "\n",
    "\n",
    "* **RetrievalQAChain** â†’ RAG-style Q\\&A over docs.\n",
    "\n",
    "\n",
    "* **Custom Chains** â†’ special workflows not covered by above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bc4040",
   "metadata": {},
   "source": [
    "## âœ… Summary\n",
    "\n",
    "* **Chains = reusable pipelines** for LLM apps.\n",
    "\n",
    "\n",
    "* They let you combine prompts, LLMs, retrievers, tools, and custom logic.\n",
    "\n",
    "\n",
    "* Choose chain type depending on whether you need **linear workflow, branching, multiple variables, retrieval, or custom logic**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac07547c",
   "metadata": {},
   "source": [
    "# SESSION 8 : What are Runnables in LangChain | Generative AI using LangChain | Video 8 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab476b3",
   "metadata": {},
   "source": [
    "https://youtu.be/u3b-W1NgYa4?list=PLKnIA16_RmvaTbihpo4MtzVm4XOQa0ER0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd80c8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51f1fe70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d93a6bb3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "013a060b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c0a966a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e157d43a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fcd74b23",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b290a36",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3a4d5ab",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2c033702",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1158caed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313012b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
